---
title: network-protocol
last_update:
  date: 2023-9-17
slug: /2023/network-protocol
---




## 网络协议


### 数据包在TCP/IP中流转的大概流程? 数据包怎么产生? 每一层怎么处理?

- `物理层`。*因为基于物理电路，所以需要一个将数据转化为物理信号的层*
- `数据链路层`。*(ARP 协议) 用于 IP 地址与物理地址的对应 (物理地址是数据链路层和物理层使用的地址，IP 地址是网络层和以上各层使用的地址，是一种逻辑地址)*（数据链路层的主协议是 ARP）
- `网络层`（组装数据包 + 寻址（路由）+ 尝试发送）。*网络层负责`ip 数据包的产生`以及`ip 数据包在逻辑网络上的路由转发`*（无法直接用 MAC 寻址，需要先使用 IP 地址）（*header 验证 (主要功能)，以及`分片`、`重组`和`路由`*）
    - 其中，`IP 协议`提供的是不可靠的服务，他只是尽可能快地将分组从源节点送到目的节点。
    - 其他`IP 协议的附属协议`做了一下优化。比如`BGP 等路由协议族`保证最短路径。`ICMP/IGMP`则保证包在网络上的正常传输 (给传输层以保障，如果错误则直接返回错误)。
- `传输层`（发送数据包）。*网络层已经解决了基本的发送数据包的问题，传输层的目的则是，针对不同的需求，产生了不同的传输层协议*（比如有一些特殊的需求，有的人想要连接快，不介意丢包，有的人想要连接稳定）。
- `应用层`。*传输层已经根据各种需求，封装了不同的传输层协议*。应用层将需求细化，根据我们的实际使用封装了各种供我们直接使用的协议。

---

DNS 协议，把我们的 url 解析成 IP

ARP 负责解决下一跳网关 IP 的 MAC 地址，让网关能够得到目标 MAC，从而完成以太网帧的封装

- TCP 确保数据包的可靠传输
- IP 可以想象成一个门牌号
- HTTP 则是快递包里的具体数据

*物理层：因为基于物理电路，所以需要一个将数据转化为物理信号的层*

数据链路层的主协议是 ARP 协议 *用来实现 IP 地址到 MAC 地址的映射* (物理地址（MAC 地址）是数据链路层和物理层使用的地址，IP 地址是网络层和以上各层使用的地址，是一种逻辑地址)

*网络层负责`ip 数据包的产生`以及`ip 数据包在逻辑网络上的路由转发`。网络层的主协议是 IP 协议。* 网络层的其他协议均为 IP 协议的附属协议，比如`BGP 等路由协议族`保证最短路径。`ICMP/IGMP`则保证包在网络上的正常传输 (给传输层以保障，如果错误则直接返回错误)。

*网络层已经解决了基本的发送数据包的问题，传输层的目的则是，针对不同的需求，产生了不同的传输层协议*（比如有一些特殊的需求，有的人想要连接快，不介意丢包，有的人想要连接稳定）。

*传输层已经根据各种需求，封装了不同的传输层协议*。应用层将需求细化，根据我们的实际使用封装了各种供我们直接使用的协议。

可以用“邮局收发邮件来通信”来类比网络中数据包的收发。具体来说，向顺丰下单（第一次请求），顺丰接单（应答)，你向快递小哥联系 (回应应答)，你将消息放进盒子里 (开始封装请求，会话层)，快递小哥封装 一层盒子贴上快递单带回网店 (传输层），到快递点检查是否区域快件（网络层)，将 快件交给运输车 (链路层)，各个快递转运 中心（物理层），快件到达收件市转运中心 (物理层），转运输车（链路层），到达区 域分发（网络层)，网点派送（传输层)，快递员方面签收（会话层），拆开检查（表示层)，收到快递（应用层）。总结一下，下单、揽件、运输、派送、签收，就可以分别看作是应用层、传输层、网络层、链路层、物理层。




### segment, packet, frame, stream

*传输层的数据叫做段 segment，网络层的数据叫做包 packet，数据链路层的数据叫做帧 frame，物理层的数据叫做流 stream*

- 以太网数据包的大小是固定的，1500 字节的负载 +22 个字节的头信息=1522 字节
- IP 数据包在以太网数据包的负载里面，它也有自己的头信息，最少需要 20 个字节，所以 IP 数据包的负载最多为 1480 字节
- TCP 数据包在 IP 数据包里面。除去头信息，它的最大负载是 1460，如果超过最大负载，就需要在发送两个 TCP 数据包










## TCP



### s



TIME_WAIT 是主动断开连接的一方会出现的，与TIME_WAIT成对出现的是CLOSE_WAIT，CLOSE_WAIT出现在被动断开连接的一方，client和server都有可能出现。TIME_WAIT会持续2MSL（MSL默认2min，2MSL就是4min，但是可以自定义）之后关闭。所以在高并发场景中，一定会有大量TIME_WAIT状态。可想而知，如果大量出现这种状态，那么大量conn无法真正进入CLOSED状态，就会产生大量overhead，连接数直接被打满，无法创建新连接，导致client连接失败。解决方案也是类似的，最有效的方法当然是直接TCP长连接（而不是现在这种高并发场景导致的大量短连接）。如果无法使用长连接，那就“允许 time_wait 状态的连接可以被复用和减少 time_wait 的时间 (但是可能会存在旧连接数据包乱序和旧连接没有正常关闭的问题)”。

```markdown
TIME_WAIT 状态太多是怎么回事儿？

---

如果处于 TIMEWAIT 状态，说明双方建立成功过连接，而且已经发送了最后的 ACK 之后，才会处于这个状态，而且是主动发起关闭的一方处于这个状态。

如果存在大量的 TIMEWAIT，往往是因为短连接太多，不断的创建连接，然后释放连接，从而导致很多连接在这个状态，可能会导致无法发起新的连接。解决的方式往往是：

- 打开 tcp_tw_recycle 和 tcp_timestamps 选项；
- 打开 tcp_tw_reuse 和 tcp_timestamps 选项；
- 程序中使用 SO_LINGER，应用强制使用 rst 关闭。

当客户端收到 Connection Reset，往往是收到了 TCP 的 RST 消息，RST 消息一般在下面的情况下发送：

- 试图连接一个未被监听的服务端；
- 对方处于 TIMEWAIT 状态，或者连接已经关闭处于 CLOSED 状态，或者重新监听 seq num 不匹配；
- 发起连接时超时，重传超时，keepalive 超时；
- 在程序中使用 SO_LINGER，关闭连接时，放弃缓存中的数据，给对方发送 RST。

```

老生常谈的问题了，但是我还是不懂。

***如果存在大量的 TIMEWAIT，往往是因为短连接太多，不断的创建连接，然后释放连接，从而导致很多连接在这个状态，可能会导致无法发起新的连接。解决方案是打开 TCP_TW 的两个配置以及 tcp_timestamps 配置。***



### reliability


- EC 差错控制 (乱序问题) (checksum, seq, ack)
- FC 流量控制 (wnd, tag flow,)
- CC 拥塞控制 (packet-loss based, cwnd, ssthresh, slow start, fast retransmit)
- ARQ 机制 (丢包重传) (Fast Retransmit, After 3 DACK) 丢包重传机制和拥塞控制无关，二者都属于为了保证 TCP 可靠性的机制。丢包重传机制通常会在网络拥塞时触发，所以通常会被误认为是拥塞机制的一部分，这种认知是错误的。总结来说，专人专事，拥塞控制是用来判断网络是否拥塞的，而丢包重传是用来确保数据的可靠传输，而不是主动控制网络拥塞。


如果拿微信发消息举例，EC就是首先得确保你发送的消息没有错别字、语法错误或者信息不连贯，没有颠三倒四、前言不搭后语吧。差错控制通常通过使用校验和、循环冗余校验（CRC）等技术来实现。

- CC则是限制发送方发微信的总量，不让发送方一次发送太多（如果发送太多，就随机丢弃一些信息）。
- FC则是来匹配发送方和接收方的处理信息能力（网络好、接收方能力强就多发，否则就少发），所以需要给重要信息打个 tag，优先处理。
- 滑动窗口：是一种用于流量控制和拥塞控制的技术，它允许发送方在等待确认之前发送一定数量的数据。在微信聊天中，这可以想象为一个“缓冲区”，里面包含了你已经发送但还未得到确认的消息。如果缓冲区满了，你就需要等待一些消息得到确认后再继续发送。
- 拥塞窗口：是拥塞控制中的一个概念，它限制了发送方在任何给定时间可以发送的数据量。在微信聊天的比喻中，这相当于你根据网络状况和对方的接收能力来调整你一次能发送的消息数量。






### BBR

```markdown
1 设备缓存会导致延时？

假如经过设备的包都不需要进入缓存，那么得到的速度是最快的。进入缓存且等待，等待的时间就是额外的延时。BBR 就是为了避免这些问题：

充分利用带宽；降低 buffer 占用率。

2 降低发送 packet 的速度，为何反而提速了？

标准 TCP 拥塞算法是遇到丢包的数据时快速下降发送速度，因为算法假设丢包都是因为过程设备缓存满了。快速下降后重新慢启动，整个过程对于带宽来说是浪费的。通过 packet 速度—时间的图来看，从积分上看，BBR 充分利用带宽时发送效率才是最高的。可以说 BBR 比标准 TCP 拥塞算法更正确地处理了数据丢包。对于网络上有一定丢包率的公网，BBR 会更加智慧一点。

回顾网络发展过程，带宽的是极大地改进的，而最小延迟会受限与介质传播速度，不会明显减少。BBR 可以说是应运而生。

3 BBR 如何解决延时？

S1：慢启动开始时，以前期的延迟时间为延迟最小值 Tmin。然后监控延迟值是否达到 Tmin 的 n 倍，达到这个阀值后，判断带宽已经消耗尽且使用了一定的缓存，进入排空阶段。

S2：指数降低发送速率，直至延迟不再降低。这个过程的原理同 S1

S3：协议进入稳定运行状态。交替探测带宽和延迟，且大多数时间下都处于带宽探测阶段。

深夜读了 BBR 的论文和网上大牛的讲解得出的小结，分享给大家，过程比较匆忙，不足之处也望老师能指出指正。

```





### KCP


- `RTO不翻倍`，TCP 超时 RTO 更新直接 x2，而 KCP 开启快速模式只 x1.5，很厉害
- `选择性重传`，只传输丢失的数据包，TCP 会全部重传丢包之后的全部数据包
- `快速重传`，不会等到超时
- `非延迟ACK`，TCP 会延迟发送 ACK，KCP 可以设置是否延迟
- `KCP协议，除了单独的ACK包外，所有包都有UNA信息`，ARQ 模型响应有两种，UNA（此编号前所有包已收到，如 TCP）和 ACK（该编号包已收到），光用 UNA 将导致全部重传，光用 ACK 则丢失成本太高，以往协议都是二选其一
- `非退让流控`，发送窗口可以只取决于发送缓存大小和接收端剩余接收缓存大小，KCP 正常模式同 TCP 一样使用公平退让法则，即发送窗口大小由：`发送缓存大小`、`接收端剩余接收缓存大小`、`丢包退让`及`慢启动`这四要素决定。但传送及时性要求很高的小数据时，可选择通过配置跳过后两步，仅用前两项来控制发送频率。






KCP 为了实现选择性重传（ARQ），会维护一个接收窗口（滑动窗口）。如果收到有序数据会将其放到接收队列，以待应用层消费。如果存在包丢失，会判断。超过设置的次数，会让其选择重传对应的包。其实就是通过一个 rcv_nxt（接收窗口当前偏移）来判断当前需要接受的数据包。如果收到的包在窗口范围，但是不是 rcv_nxt。先保存，等包连续之后才会将连续的数据包放入到接受队列供应用层消费。同样网络不好的情况，KCP 也会实现拥塞控制，限制发送端的包。

KCP 的 ARQ 机制与 TCP 类似，只是部分策略不同，学习 KCP 也有利于我们理解 TCP


## IP协议族





        我总结一下 IP 协议的核心知识点（我总觉得自己对这块知识的掌握比较一般）

        - IP 地址，比如什么 CIDR、子网掩码、广播地址、组播地址、环回接口 loopback
        - IP 包
        - 路由协议族，RIP、OSPF、BGP
        - ICMP 协议
        - 除此之外还有 ARP 协议、DHCP 协议、PXE

        这么来看其实也还好。

### IP 协议是什么？解决了什么问题？IP 地址是什么？为啥有了IP，为啥还要 MAC？或者反过来，有了 MAC，为啥还要 IP？



- IP 协议是网络层协议，这里提纲挈领地提两个观点：
- *IP 协议是网络层协议的主协议，网络层其他协议都是为了拓展和保障 IP 协议存在的*
- *IP 不是面向连接的，从设计时，就被认为是不可靠的，是尽力而为的协议*，所以同一个连接的每个 IP 包都可以自由选择路径，到每一个路由器，都自己去找下一跳，丢了就丢了，是*靠上一层 TCP 的重发来保证可靠性*
- *IP 协议解决了多个局域网的通信问题。IP 地址就是 IP 协议定义的一套地址规则*

***IP 层解决远程定位问题，MAC 是没有远程定位功能的，只能通过本地 ARP 的方式找到。***

```markdown
IP 是地址，有定位功能；MAC 是身份证，无定位功能；

CIDR 可以用来判断是不是本地人；
```

```markdown
IP 头和 MAC 头哪些变、哪些不变？

对于 IP 头和 MAC 头哪些变、哪些不变的问题，可以分两种类型。我把它们称为“欧洲十国游”型和“玄奘西行”型。

之前我说过，MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于 IP 地址是否改变。不改变 IP 地址的网关，我们称为转发网关；改变 IP 地址的网关，我们称为 NAT 网关。
```



### OSPF、BGP、RIP 和 graph


```markdown

1.距离矢量路由算法
第一大类的算法称为距离矢量路由（distance vector routing）。它是基于 Bellman-Ford 算法的。

这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。

由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

2.链路状态路由算法
第二大类算法是链路状态路由（link state routing），基于 Dijkstra 算法。

这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。

不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。

```


```markdown
1.基于链路状态路由算法的 OSPF
OSPF（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称 IGP）。

内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。

这一点非常重要。有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。这个在后面我们讲数据中心的网络的时候，一般应用的接入层会有负载均衡 LVS。它可以和 OSPF 一起，实现高吞吐量的接入层设计。

有了内网的路由协议，在一个国家内，唐僧可以想怎么走怎么走了，两条路选一条也行。

---

2.基于距离矢量路由算法的 BGP

但是外网的路由协议，也即国家之间的，又有所不同。我们称为外网路由协议（Border Gateway Protocol，简称 BGP）。

在一个国家内部，有路当然选近的走。但是国家之间，不光远近的问题，还有政策的问题。例如，唐僧去西天取经，有的路近。但是路过的国家看不惯僧人，见了僧人就抓。例如灭法国，连光头都要抓。这样的情况即便路近，也最好绕远点走。

对于网络包同样，每个数据中心都设置自己的 Policy。例如，哪些外部的 IP 可以让内部知晓，哪些内部的 IP 可以让外部知晓，哪些可以通过，哪些不能通过。这就好比，虽然从我家里到目的地最近，但是不能谁都能从我家走啊！

在网络世界，这一个个国家成为自治系统 AS（Autonomous System）。自治系统分几种类型。

Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。

Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大公司的网络。

Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。

每个自治系统都有边界路由器，通过它和外面的世界建立联系。

BGP 又分为两类，eBGP 和 iBGP。自治系统间，边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。边界路由器如何将 BGP 学习到的路由导入到内部网络呢？就是通过运行 iBGP，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。

BGP 协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版。

前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在 BGP 里面，除了下一跳 hop 之外，还包括了自治系统 AS 的路径，从而可以避免坏消息传得慢的问题，也即上面所描述的，B 知道 C 原来能够到达 A，是因为通过自己，一旦自己都到达不了 A 了，就不用假设 C 还能到达 A 了。

另外，在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。就像大家都能记住出去玩，从中国出发先到韩国然后到日本，只要不计算细到具体哪一站，就算是发送全局信息，也是没有问题的。

```

```markdown
RIP（Routing Information Protocol）是一种距离向量路由协议，主要用于小型网络中。它使用跳数（hop count）作为衡量路径优劣的指标，并通过将路由表信息广播到相邻路由器来实现路由的学习和更新。RIP 协议对网络的规模和拓扑变化的适应性较差，因此在大型网络中使用较少。相比之下，OSPF（Open Shortest Path First）和 BGP（Border Gateway Protocol）是链路状态路由协议，具有更高的灵活性和可扩展性。OSPF 协议使用链路状态数据库和 Dijkstra 算法来计算最短路径，适用于中等规模的企业网络。BGP 协议是一个可实现自治系统之间路由选择的协议，主要用于互联网的外部路由选择。

总的来说，RIP 协议适用于小型网络，使用跳数作为路径选择的度量标准；OSPF 协议适用于中等规模的企业网络，使用链路状态数据库和最短路径算法；BGP 协议适用于互联网的外部路由选择。
```


*其实按照我的理解，OSPF 和 BGP 的本质区别在于能否解决负权边问题是吗？OSPF 使用 Dijkstra 算法，BGP 使用 Bellman-Ford 算法，这两个算法的核心区别就是是否能够解决负权边和负权环问题。AS 就是这里的负权边嘛。*

***还是拿收发邮件举例来说明，静态路由就是您自己在小区（局域网）里溜达问题着玩，但是除了小区，就要用导航（网关）了，网关会（根据 OSPF、BGP、RIP 等路由协议）自动更新路由表，自动规划出最合理的路由。***





### 那在网络层发送数据包时，会自动选择 OSPF 或者 BGP 吗？




```markdown

在网络层发送数据包时，通常不会自动选择 OSPF 或 BGP。OSPF 和 BGP 是动态路由协议，用于学习和更新路由表。它们通常在路由器之间运行，并根据网络拓扑和策略来决定最佳路由。当一个路由器接收到数据包时，它会使用路由表来决定将数据包发送到哪个接口。路由表中的路由可以通过静态路由配置手动添加，也可以通过动态路由协议自动学习和更新。

在选择最佳路由时，动态路由协议通常会考虑各种因素，如链路质量、网络拓扑和策略。不同的动态路由协议有不同的算法和策略来选择最佳路由。例如，OSPF 使用链路状态信息来计算最短路径，而 BGP 使用路径属性和策略来选择路由。

所以，路由器通常会根据路由表中的最佳匹配来选择路由，而不是自动选择 OSPF 或 BGP。选择使用哪种路由协议取决于网络的需求、策略和拓扑结构。

---

也就是说，网关还集成了自动更新路由表的功能？我们不需要选择 OSPF 还是 BGP，这个是网关需要做的事情，网关会自动更新路由表，并给网络层的数据包提供最合理的路由，是吗？

---

是的，你说得没错。网关会自动更新路由表，并根据网络层的数据包选择最合理的路由。这是动态路由的特性。在动态路由中，网关会使用路由协议来学习并更新路由表。常见的动态路由协议包括 RIP（Routing Information Protocol）、OSPF（Open Shortest Path First）和 BGP（Border Gateway Protocol）。这些协议会根据网络拓扑和其他因素自动计算出最佳的路由，并将路由信息与其他路由器交换，以保持网络的连通性和适应性。

相比之下，静态路由需要手动配置路由表项。在静态路由中，管理员需要手动指定每个网络的下一跳路由器。这种方式适用于规模较小或拓扑变化有限的网络。静态路由的配置相对简单，但需要手动维护，不会自动适应网络变化。

总的来说，动态路由提供了更大的灵活性和可靠性，但需要进行计算和交换路由信息。而静态路由则更简单，但需要手动维护。选择使用静态路由还是动态路由取决于网络的规模、复杂程度以及管理要求等因素。

希望这个例子能帮助你理解静态和动态路由在日常生活中的应用。有其他问题的话，请随时提问。

```




## HTTP



### HTTP headers type?


RFC2616定义了HTTP/1.1的47个fields，之后还有RFC4229等添加其他fields，现在归IANA管理

general, request, response, entity

- 通用 header（general header fields, 请求报文和响应报文都会使用的 header）
- 请求 header（request header fields, 从客户端向服务器端发送请求报文时使用的 header；补充了请求的附加内容，客户端信息，响应内容相关优先级等信息）
- 响应 header（response header fields, 从服务器端向客户端返回响应报文时使用的 header；补充了响应的附加内容，也会要求客户端附加额外的内容信息）
- 实体 header（entity header fields, 针对请求报文和响应报文的实体部分使用的 header；补充了资源内容更新时间等与实体有关的信息）



###  一个 tcp 连接能发几个 http 请求? http能不能一次连接多次请求，不等后端返回?


```markdown
如果是HTTP 1.0 版本协议，一般情况下，不支持长连接，因此在每次请求发送完毕之后，TCP连接即会断开，因此一个TCP发送一个HTTP请求，但是有一种情况可以将一条TCP连接保持在活跃状态，那就是通过Connection和Keep-Alive首部，在请求头带上 Connection: Keep-Alive ，并且可以通过Keep-Alive 通用首部中指定的，用逗号分隔的选项调节keep-alive的行为，如果客户端和服务端都支持，那么其实也可以发送多条，不过此方式也有限制，可以关注《HTTP 权威指南》4.5.5 节对于Keep-Alive连接的限制和规则；
而如果是HTTP 1.1 版本协议，支持了长连接，因此只要TCP连接不断开，便可以一直发送HTTP请求，持续不断，没有上限；
同样，如果是HTTP 2.0 版本协议，支持多用复用，一个TCP连接是可以并发多个HTTP请求的，同样也是支持长连接，因此只要不断开TCP的连接，HTTP请求数也是可以没有上限地持续发送，
```

也就是说这个问题是由HTTP决定的，因为TCP默认长连接，HTTP和TCP之间永远都是连接状态的，所以我们只要保证HTTP是长连接的，整个链路就打通了。



### HTTP 状态码 304 的具体原理?


- *有缓存，且缓存已过期时*，将 header 里的`If-Modified-Since`，`If-None-Match`这两个参数与服务器进行对比
- 如果相同，则获取本地的缓存信息，返回 304
- 如果不同，则服务器返回新的资源，返回 200。并将`Last-Modified`，`ETag`重置。
- *ETag 的优先级高于 Last-Modified*，其中，Etag 是对资源的`INode`，`size`和`最后修改时间 MTime`进行 Hash 后得到的，是对于资源的唯一标识。`Last-Modified`是资源被修改的最后时间


### HTTP 状态码 301/308、303/307 的区别


redirect(permanent/temporary), qs(get/post), (browser caching)

永久重定向，301 和 308(308 是 301 的补充)

- 301，允许。
- 308，不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。

临时重定向的 3 个：302,303,307(303 和 307 都是 HTTP1.1 对于 302 的细化，目前 302 状态没用)

*其实所谓的`永久`和`临时`，本质上来说是`浏览器缓存`的问题*。

301 会缓存该 url 到浏览器，有效期通常为 100d，请求时，会直接从缓存中取出该短链映射的 url，返回时在 header 中添加参数`Location: url`指定原链接。而 302 还是会跳转到原 url，所以被称为“临时重定向”。




### HTTP2


HTTP2 解决了 HTTP1.1 中的队头阻塞问题，但是为什么 HTTP1.1 有队头阻塞问题，HTTP2 究竟怎么解决的很多人都不清楚。

其实“队头阻塞”是一个专有名词，不仅仅这里有，交换器等其他都有这个问题，引起这个问题的根本原因是使用了队列这种数据结构。

对于同一个 tcp 连接，所有的 http1.0 请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求，这个阻塞主要发生在客户端。

这就好像我们在等红绿灯，即使旁边绿灯亮了，你的这个车道是红灯，你还是不能走，还是要等着。

对于同一个 tcp 连接，http1.1 允许一次发送多个 http1.1 请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了 http1.0 的客户端的队头阻塞。但是，http1.1 规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送。也会造成队头阻塞。可见，http1.1 的队首阻塞发生在服务器端。
